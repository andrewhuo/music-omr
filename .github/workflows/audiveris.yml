name: Audiveris OMR + Barline Detection Test

on:
    workflow_dispatch:
      inputs:
        pdf_gcs_uri:
          description: "GCS URI to your input PDF (gs://music-omr-bucket-777135743132/input/test.pdf)"
          required: true
          type: string


jobs:
  pipeline:
    runs-on: ubuntu-latest
    env:
      BUCKET: "gs://music-omr-bucket-777135743132"
      OUTPUT_PREFIX: "gs://music-omr-bucket-777135743132/output"


    permissions:
      contents: read
      id-token: write

    steps:
      #################################################################
      # 1) Checkout and authenticate
      #################################################################
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}

      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v3
        with:
          version: ">= 363.0.0"

      - name: Show inputs
        run: |
          echo "Input PDF: ${{ inputs.pdf_gcs_uri }}"
          echo "Output prefix (fixed): ${OUTPUT_PREFIX}"

      #################################################################
      # 2) Wipe everything except input/ and output/ in the main bucket
      #################################################################
      - name: Wipe non-input/output prefixes in main bucket
        shell: bash
        run: |
          set -euo pipefail

          BUCKET="gs://music-omr-bucket-777135743132"
          KEEP_INPUT="${BUCKET}/input/"
          KEEP_OUTPUT="${BUCKET}/output/"

          echo "Bucket: ${BUCKET}"
          echo "Keeping: ${KEEP_INPUT}"
          echo "Keeping: ${KEEP_OUTPUT}"
          echo "Listing top-level entries..."

          # Top-level listing (prefixes and any root objects)
          mapfile -t ITEMS < <(gsutil ls -d "${BUCKET}/*" 2>/dev/null || true)

          if [[ ${#ITEMS[@]} -eq 0 ]]; then
            echo "No top-level entries found (or none visible)."
            exit 0
          fi

          echo "Top-level entries:"
          printf '  %s\n' "${ITEMS[@]}"

          for ITEM in "${ITEMS[@]}"; do
            # Keep only input/ and output/
            if [[ "$ITEM" == "$KEEP_INPUT" || "$ITEM" == "$KEEP_OUTPUT" ]]; then
              echo "KEEP   $ITEM"
              continue
            fi

            echo "DELETE $ITEM"

            # If it's a "prefix" (ends with /), delete everything under it.
            # The ** pattern matches all objects under that prefix.
            if [[ "$ITEM" == */ ]]; then
              gsutil -m rm -r "${ITEM}**" || true

              # Also try to remove any legacy "folder placeholder" object names, if they exist.
              gsutil rm "${ITEM}" 2>/dev/null || true
              gsutil rm "${ITEM%/}_$folder$" 2>/dev/null || true
            else
              # It's a root-level object (like the weird outputgs:// object)
              gsutil rm "$ITEM" || true
            fi
          done

          echo "Cleanup complete."


      #################################################################
      # 3) Clean output prefix (delete all previous outputs)
      #################################################################
      - name: Wipe old outputs
        run: |
          set -euo pipefail
          echo "Deleting all objects under: ${OUTPUT_PREFIX}"
          gsutil -m rm -r "${OUTPUT_PREFIX}/**" || echo "No objects to delete"

      #################################################################
      # 4) Download the input PDF
      #################################################################
      - name: Download input PDF
        run: |
          set -euo pipefail
          mkdir -p /tmp/work
          gsutil cp "${{ inputs.pdf_gcs_uri }}" /tmp/work/input.pdf
          echo "Input PDF:"
          ls -lh /tmp/work/input.pdf

      #################################################################
      # 5) Run Audiveris OMR 
      #################################################################
      - name: Run Audiveris OMR
        run: |
          set -euo pipefail
          mkdir -p /tmp/work/audiveris_out
          docker pull toprock/audiveris:latest

          # Use the actual executable inside the image
          docker run --rm \
            -v /tmp/work:/work \
            toprock/audiveris:latest \
            /audiveris-extract/bin/Audiveris -batch -export -output /work/audiveris_out /work/input.pdf || true

          echo "Audiveris output contents:"
          find /tmp/work/audiveris_out -maxdepth 4 -type f -print || true
          

      #################################################################
      # 6) Inspect OMR contents (debug)
      #################################################################
      - name: Inspect OMR contents (debug)
        run: |
          set -euo pipefail
          OMR="/tmp/work/audiveris_out/input/input.omr"

          echo "== List .omr archive =="
          unzip -l "$OMR" | sed -n '1,200p'

          SHEET_XML="$(unzip -l "$OMR" | awk '{print $4}' | grep -E '^sheet#.+/sheet#.+\.xml$' | head -n 1 || true)"
          if [ -z "$SHEET_XML" ]; then
            echo
            echo "No sheet XML found inside .omr (only book.xml was saved)."
            echo "Showing Audiveris log tail to diagnose:"
            LOG="$(ls -1 /tmp/work/audiveris_out/input/*.log 2>/dev/null | head -n 1 || true)"
            if [ -n "$LOG" ]; then
              echo "Log: $LOG"
              tail -n 200 "$LOG" || true
            else
              echo "No log file found in /tmp/work/audiveris_out/input/"
            fi
            exit 0
          fi

          echo
          echo "== Found sheet XML: $SHEET_XML =="
          unzip -p "$OMR" "$SHEET_XML" | sed -n '1,200p'

          echo
          echo "== Grep likely geometry keywords =="
          unzip -p "$OMR" "$SHEET_XML" | egrep -n "System|Staff|bounds|rect|x|y|top|bottom|left|right" | head -n 200 || true

      - name: Check if any sheet XML contains multiple <page> blocks
        run: |
          set -euo pipefail
          OMR="/tmp/work/audiveris_out/input/input.omr"
          python - << 'PY'
          import re, zipfile, xml.etree.ElementTree as ET

          sheet_re = re.compile(r"^sheet#(\d+)/sheet#\1\.xml$")
          omr = "/tmp/work/audiveris_out/input/input.omr"

          with zipfile.ZipFile(omr, "r") as z:
            sheets = sorted([n for n in z.namelist() if sheet_re.match(n)])
            for path in sheets:
              root = ET.fromstring(z.read(path))
              pages = root.findall("page")
              if len(pages) != 1:
                print("\nMULTI-PAGE SHEET:", path, "page_count=", len(pages))
              for p in pages:
                pid = p.get("id")
                systems = p.findall(".//system")
                ind = [s.get("indented") for s in systems if s.get("indented") is not None]
                print(f"  sheet={path} page_id={pid} systems={len(systems)} indented_flags={ind[:5]}")
          PY


      - name: OMR structure debug (systems/staves)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, json, re, zipfile
          import xml.etree.ElementTree as ET

          omr = "/tmp/work/audiveris_out/input/input.omr"
          sheet_re = re.compile(r"^sheet#(\d+)/sheet#\1\.xml$")

          with zipfile.ZipFile(omr, "r") as z:
            sheets = []
            for name in z.namelist():
              m = sheet_re.match(name)
              if m:
                sheets.append((int(m.group(1)), name))
            sheets.sort()

            out = []
            for n, path in sheets:
              root = ET.fromstring(z.read(path))
              page = root.find("page")
              if page is None:
                out.append({"sheet": path, "page": None})
                continue

              systems_direct = page.findall("system")
              systems_all = page.findall(".//system")

              rec = {
                "sheet": path,
                "systems_direct": len(systems_direct),
                "systems_all": len(systems_all),
                "systems": [],
              }

              for sys_el in systems_all:
                sys_id = sys_el.get("id")
                indented = sys_el.get("indented")
                staves = sys_el.findall(".//staff")

                staff_recs = []
                for st in staves:
                  header = st.find("header")
                  header_start = header.get("start") if header is not None else None
                  lines = st.find("lines")
                  line_count = len(lines.findall("line")) if lines is not None else 0
                  staff_recs.append({
                    "staff_id": st.get("id"),
                    "staff_left": st.get("left"),
                    "header_start": header_start,
                    "line_count": line_count,
                  })

                rec["systems"].append({
                  "system_id": sys_id,
                  "indented": indented,
                  "staff_count": len(staves),
                  "staves": staff_recs,
                })

              out.append(rec)

          os.makedirs("/tmp/work/debug", exist_ok=True)
          p = "/tmp/work/debug/omr_structure.json"
          with open(p, "w") as f:
            json.dump(out, f, indent=2)

          print("Wrote", p)
          print("Preview:")
          with open(p, "r") as f:
            for i, line in enumerate(f):
              if i >= 200:
                break
              print(line.rstrip("\n"))
          PY

      - name: OMR anomaly summary (print only problem systems)
        run: |
          set -euo pipefail
          python - << 'PY'
          import json

          p = "/tmp/work/debug/omr_structure.json"
          with open(p, "r") as f:
              data = json.load(f)

          def staff_bad(st):
              lc = st.get("line_count", 0)
              left = st.get("staff_left")
              hs = st.get("header_start")
              return (lc is None) or (lc < 5) or (left is None) or (hs is None)

          any_printed = False
          for sheet in data:
              bad_systems = []
              for sys in sheet.get("systems", []):
                  staves = sys.get("staves", [])
                  if not staves:
                      continue
                  bad_staves = [s for s in staves if staff_bad(s)]
                  if bad_staves:
                      bad_systems.append({
                          "system_id": sys.get("system_id"),
                          "indented": sys.get("indented"),
                          "staff_count": sys.get("staff_count"),
                          "bad_staves": bad_staves,
                      })

              if bad_systems:
                  any_printed = True
                  print("\nSHEET:", sheet.get("sheet"))
                  print("systems_direct:", sheet.get("systems_direct"), "systems_all:", sheet.get("systems_all"))
                  for bs in bad_systems:
                      print("  SYSTEM id=", bs["system_id"], "indented=", bs["indented"], "staff_count=", bs["staff_count"])
                      for s in bs["bad_staves"]:
                          print("    staff_id=", s.get("staff_id"),
                                "line_count=", s.get("line_count"),
                                "staff_left=", s.get("staff_left"),
                                "header_start=", s.get("header_start"))

          if not any_printed:
              print("\nNo anomalies found: all staves had line_count>=5 and left/header_start present.")
          PY

      #################################################################
      # 7) Python setup & dependencies
      #################################################################
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install opencv-python==4.12.0.88 pymupdf==1.20.0 numpy

      #################################################################
      # 8) Annotate measures on PDF
      #################################################################
      - name: Draw staff guides from Audiveris OMR
        run: |
          set -euo pipefail
          python -u parser-api/annotate_guides_from_omr.py \
            /tmp/work/input.pdf \
            /tmp/work/audiveris_out/input/input.omr \
            /tmp/work/annotated.pdf
          echo "Annotated PDF:"
          ls -lh /tmp/work/annotated.pdf

      - name: Sanity check annotated PDF page count
        run: |
          set -euo pipefail
          python - << 'PY'
          import fitz
          in_doc = fitz.open("/tmp/work/input.pdf")
          out_doc = fitz.open("/tmp/work/annotated.pdf")
          print("input pages:", in_doc.page_count)
          print("output pages:", out_doc.page_count)
          if in_doc.page_count != out_doc.page_count:
              raise SystemExit("ERROR: annotated.pdf page count does not match input.pdf")
          PY


      #################################################################
      # 9) Upload ALL outputs to GCS
      #################################################################
      - name: Upload outputs to GCS
        run: |
          set -euo pipefail

          # Annotated PDF
          gsutil cp /tmp/work/annotated.pdf "${OUTPUT_PREFIX}/annotated.pdf"

          # Audiveris outputs (only if present)
          if [ -d /tmp/work/audiveris_out ] && [ "$(ls -A /tmp/work/audiveris_out)" ]; then
            echo "Uploading Audiveris outputs"
            gsutil -m cp -r /tmp/work/audiveris_out "${OUTPUT_PREFIX}/audiveris_out"
          else
            echo "No Audiveris outputs to upload"
          fi

          echo "All uploads complete"

