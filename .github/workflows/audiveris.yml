name: Audiveris OMR + Barline Detection Test

on:
  workflow_dispatch:
    inputs:
      pdf_gcs_uri:
        description: "GCS URI to your input PDF (gs://music-omr-bucket-777135743132/input/test.pdf)"
        required: true
        type: string

jobs:
  pipeline:
    runs-on: ubuntu-latest
    env:
      BUCKET: "gs://music-omr-bucket-777135743132"
      OUTPUT_PREFIX: "gs://music-omr-bucket-777135743132/output"

      # ====== Debug targeting knobs (EDIT THESE) ======
      # Based on your earlier description: "5th one down on the 3rd page"
      # Start with sheet#3 and staff id 5. If itâ€™s not the right one, change STAFF.
      DEBUG_SHEET: "sheet#3/sheet#3.xml"
      DEBUG_STAFF: "5"

    permissions:
      contents: read
      id-token: write

    steps:
      #################################################################
      # 1) Checkout and authenticate
      #################################################################
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}

      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v3
        with:
          version: ">= 363.0.0"

      - name: Show inputs
        run: |
          echo "Input PDF: ${{ inputs.pdf_gcs_uri }}"
          echo "Output prefix (fixed): ${OUTPUT_PREFIX}"
          echo "DEBUG_SHEET: ${DEBUG_SHEET}"
          echo "DEBUG_STAFF: ${DEBUG_STAFF}"

      #################################################################
      # 2) Wipe everything except input/ and output/ in the main bucket
      #################################################################
      - name: Wipe non-input/output prefixes in main bucket
        shell: bash
        run: |
          set -euo pipefail

          BUCKET="gs://music-omr-bucket-777135743132"
          KEEP_INPUT="${BUCKET}/input/"
          KEEP_OUTPUT="${BUCKET}/output/"

          echo "Bucket: ${BUCKET}"
          echo "Keeping: ${KEEP_INPUT}"
          echo "Keeping: ${KEEP_OUTPUT}"
          echo "Listing top-level entries..."

          mapfile -t ITEMS < <(gsutil ls -d "${BUCKET}/*" 2>/dev/null || true)

          if [[ ${#ITEMS[@]} -eq 0 ]]; then
            echo "No top-level entries found (or none visible)."
            exit 0
          fi

          echo "Top-level entries:"
          printf '  %s\n' "${ITEMS[@]}"

          for ITEM in "${ITEMS[@]}"; do
            if [[ "$ITEM" == "$KEEP_INPUT" || "$ITEM" == "$KEEP_OUTPUT" ]]; then
              echo "KEEP   $ITEM"
              continue
            fi

            echo "DELETE $ITEM"
            if [[ "$ITEM" == */ ]]; then
              gsutil -m rm -r "${ITEM}**" || true
              gsutil rm "${ITEM}" 2>/dev/null || true
              gsutil rm "${ITEM%/}_$folder$" 2>/dev/null || true
            else
              gsutil rm "$ITEM" || true
            fi
          done

          echo "Cleanup complete."

      #################################################################
      # 3) Clean output prefix (delete all previous outputs)
      #################################################################
      - name: Wipe old outputs
        run: |
          set -euo pipefail
          echo "Deleting all objects under: ${OUTPUT_PREFIX}"
          gsutil -m rm -r "${OUTPUT_PREFIX}/**" || echo "No objects to delete"

      #################################################################
      # 4) Download the input PDF
      #################################################################
      - name: Download input PDF
        run: |
          set -euo pipefail
          mkdir -p /tmp/work
          gsutil cp "${{ inputs.pdf_gcs_uri }}" /tmp/work/input.pdf
          echo "Input PDF:"
          ls -lh /tmp/work/input.pdf

      #################################################################
      # 5) Run Audiveris OMR
      #################################################################
      - name: Run Audiveris OMR
        run: |
          set -euo pipefail
          mkdir -p /tmp/work/audiveris_out
          docker pull toprock/audiveris:latest

          docker run --rm \
            -v /tmp/work:/work \
            toprock/audiveris:latest \
            /audiveris-extract/bin/Audiveris -batch -export -output /work/audiveris_out /work/input.pdf || true

          echo "Audiveris output contents:"
          find /tmp/work/audiveris_out -maxdepth 4 -type f -print || true

      #################################################################
      # 6) Inspect OMR contents (quick sanity)
      #################################################################
      - name: Inspect OMR contents (debug)
        run: |
          set -euo pipefail
          OMR="/tmp/work/audiveris_out/input/input.omr"

          echo "== List .omr archive =="
          unzip -l "$OMR" | sed -n '1,200p'

          SHEET_XML="$(unzip -l "$OMR" | awk '{print $4}' | grep -E '^sheet#.+/sheet#.+\.xml$' | head -n 1 || true)"
          if [ -z "$SHEET_XML" ]; then
            echo
            echo "No sheet XML found inside .omr (only book.xml was saved)."
            echo "Showing Audiveris log tail to diagnose:"
            LOG="$(ls -1 /tmp/work/audiveris_out/input/*.log 2>/dev/null | head -n 1 || true)"
            if [ -n "$LOG" ]; then
              echo "Log: $LOG"
              tail -n 200 "$LOG" || true
            else
              echo "No log file found in /tmp/work/audiveris_out/input/"
            fi
            exit 1
          fi

          echo
          echo "== Found sheet XML (first one): $SHEET_XML =="

      #################################################################
      # 7) Multi-page sheet check (kept)
      #################################################################
      - name: Check if any sheet XML contains multiple <page> blocks
        run: |
          set -euo pipefail
          OMR="/tmp/work/audiveris_out/input/input.omr"
          python - << 'PY'
          import re, zipfile, xml.etree.ElementTree as ET

          sheet_re = re.compile(r"^sheet#(\d+)/sheet#\1\.xml$")
          omr = "/tmp/work/audiveris_out/input/input.omr"

          with zipfile.ZipFile(omr, "r") as z:
            sheets = sorted([n for n in z.namelist() if sheet_re.match(n)])
            for path in sheets:
              root = ET.fromstring(z.read(path))
              pages = root.findall("page")
              if len(pages) != 1:
                print("\nMULTI-PAGE SHEET:", path, "page_count=", len(pages))
              for p in pages:
                pid = p.get("id")
                systems = p.findall(".//system")
                ind = [s.get("indented") for s in systems if s.get("indented") is not None]
                print(f"  sheet={path} page_id={pid} systems={len(systems)} indented_flags={ind[:5]}")
          PY

      #################################################################
      # 8) OMR structure debug (FIXED: handles multiple <page>)
      #################################################################
      - name: OMR structure debug (systems/staves) - all pages
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, json, re, zipfile
          import xml.etree.ElementTree as ET

          omr = "/tmp/work/audiveris_out/input/input.omr"
          sheet_re = re.compile(r"^sheet#(\d+)/sheet#\1\.xml$")

          with zipfile.ZipFile(omr, "r") as z:
            sheets = []
            for name in z.namelist():
              m = sheet_re.match(name)
              if m:
                sheets.append((int(m.group(1)), name))
            sheets.sort()

            out = []
            for _, path in sheets:
              root = ET.fromstring(z.read(path))
              pages = root.findall("page")

              rec = {
                "sheet": path,
                "page_count": len(pages),
                "pages": [],
              }

              for page in pages:
                pid = page.get("id")
                systems_all = page.findall(".//system")

                page_rec = {
                  "page_id": pid,
                  "systems_all": len(systems_all),
                  "systems": [],
                }

                for sys_el in systems_all:
                  sys_id = sys_el.get("id")
                  indented = sys_el.get("indented")
                  staves = sys_el.findall(".//staff")

                  staff_recs = []
                  for st in staves:
                    header = st.find("header")
                    header_start = header.get("start") if header is not None else None
                    lines = st.find("lines")
                    line_count = len(lines.findall("line")) if lines is not None else 0
                    staff_recs.append({
                      "staff_id": st.get("id"),
                      "staff_left": st.get("left"),
                      "header_start": header_start,
                      "line_count": line_count,
                    })

                  page_rec["systems"].append({
                    "system_id": sys_id,
                    "indented": indented,
                    "staff_count": len(staves),
                    "staves": staff_recs,
                  })

                rec["pages"].append(page_rec)

              out.append(rec)

          os.makedirs("/tmp/work/debug", exist_ok=True)
          p = "/tmp/work/debug/omr_structure.json"
          with open(p, "w") as f:
            json.dump(out, f, indent=2)

          print("Wrote", p)
          print("Preview:")
          with open(p, "r") as f:
            for i, line in enumerate(f):
              if i >= 120:
                break
              print(line.rstrip("\n"))
          PY

      #################################################################
      # 9) Dump target staff XML (so we see header/clef/lines raw)
      #################################################################
      - name: Dump target staff XML (for DEBUG_SHEET/DEBUG_STAFF)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, zipfile, xml.etree.ElementTree as ET

          omr = "/tmp/work/audiveris_out/input/input.omr"
          target_sheet = os.environ["DEBUG_SHEET"]
          target_staff = os.environ["DEBUG_STAFF"]

          out_dir = "/tmp/work/debug"
          os.makedirs(out_dir, exist_ok=True)
          out_path = os.path.join(out_dir, f"staff_dump_{target_sheet.replace('/','_')}_staff{target_staff}.xml.txt")

          with zipfile.ZipFile(omr, "r") as z:
            root = ET.fromstring(z.read(target_sheet))
            pages = root.findall("page")
            found = False
            with open(out_path, "w") as f:
              for page in pages:
                for sys_el in page.findall(".//system"):
                  for st in sys_el.findall(".//staff"):
                    if (st.get("id") or "") == target_staff:
                      f.write(f"FOUND staff id={target_staff} system_id={sys_el.get('id')} page_id={page.get('id')}\n\n")
                      f.write(ET.tostring(st, encoding="unicode"))
                      f.write("\n")
                      found = True
                      break
                  if found:
                    break
                if found:
                  break

              if not found:
                f.write(f"Did not find staff id={target_staff} in {target_sheet}\n")

          print("Wrote", out_path)
          PY

      #################################################################
      # 10) Python setup & dependencies
      #################################################################
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install opencv-python==4.12.0.88 pymupdf==1.20.0 numpy

      #################################################################
      # 11) Draw staff guides (targeted debug only)
      #################################################################
      - name: Draw staff guides from Audiveris OMR
        env:
          DEBUG_GUIDES: "1"
          DEBUG_GUIDES_SHEET: "${{ env.DEBUG_SHEET }}"
          DEBUG_GUIDES_STAFF_ID: "${{ env.DEBUG_STAFF }}"
          DEBUG_GUIDES_DUMP_INTERS: "1"
        run: |
          set -euo pipefail
          python -u parser-api/annotate_guides_from_omr.py \
            /tmp/work/input.pdf \
            /tmp/work/audiveris_out/input/input.omr \
            /tmp/work/annotated.pdf
          echo "Annotated PDF:"
          ls -lh /tmp/work/annotated.pdf

      - name: Sanity check annotated PDF page count
        run: |
          set -euo pipefail
          python - << 'PY'
          import fitz
          in_doc = fitz.open("/tmp/work/input.pdf")
          out_doc = fitz.open("/tmp/work/annotated.pdf")
          print("input pages:", in_doc.page_count)
          print("output pages:", out_doc.page_count)
          if in_doc.page_count != out_doc.page_count:
              raise SystemExit("ERROR: annotated.pdf page count does not match input.pdf")
          PY

      #################################################################
      # 12) Upload outputs + debug artifacts to GCS
      #################################################################
      - name: Upload outputs to GCS
        run: |
          set -euo pipefail

          gsutil cp /tmp/work/annotated.pdf "${OUTPUT_PREFIX}/annotated.pdf"

          # Upload debug artifacts
          if [ -d /tmp/work/debug ]; then
            gsutil -m cp -r /tmp/work/debug "${OUTPUT_PREFIX}/debug"
          fi

          # Upload Audiveris outputs
          if [ -d /tmp/work/audiveris_out ] && [ "$(ls -A /tmp/work/audiveris_out)" ]; then
            echo "Uploading Audiveris outputs"
            gsutil -m cp -r /tmp/work/audiveris_out "${OUTPUT_PREFIX}/audiveris_out"
          else
            echo "No Audiveris outputs to upload"
          fi

          echo "All uploads complete"
